{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36517.829354</td>\n",
       "      <td>43.226614</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>106.147677</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21161.721625</td>\n",
       "      <td>22.612647</td>\n",
       "      <td>0.296607</td>\n",
       "      <td>0.226063</td>\n",
       "      <td>45.283560</td>\n",
       "      <td>7.854067</td>\n",
       "      <td>0.215320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17741.250000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.245000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36932.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.885000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54682.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.090000</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72940.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          age  hypertension  heart_disease  \\\n",
       "count   5110.000000  5110.000000   5110.000000    5110.000000   \n",
       "mean   36517.829354    43.226614      0.097456       0.054012   \n",
       "std    21161.721625    22.612647      0.296607       0.226063   \n",
       "min       67.000000     0.080000      0.000000       0.000000   \n",
       "25%    17741.250000    25.000000      0.000000       0.000000   \n",
       "50%    36932.000000    45.000000      0.000000       0.000000   \n",
       "75%    54682.000000    61.000000      0.000000       0.000000   \n",
       "max    72940.000000    82.000000      1.000000       1.000000   \n",
       "\n",
       "       avg_glucose_level          bmi       stroke  \n",
       "count        5110.000000  4909.000000  5110.000000  \n",
       "mean          106.147677    28.893237     0.048728  \n",
       "std            45.283560     7.854067     0.215320  \n",
       "min            55.120000    10.300000     0.000000  \n",
       "25%            77.245000    23.500000     0.000000  \n",
       "50%            91.885000    28.100000     0.000000  \n",
       "75%           114.090000    33.100000     0.000000  \n",
       "max           271.740000    97.600000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values Handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.7    41\n",
       "28.4    38\n",
       "27.7    37\n",
       "27.6    37\n",
       "26.7    37\n",
       "        ..\n",
       "48.0     1\n",
       "49.4     1\n",
       "47.4     1\n",
       "46.6     1\n",
       "54.0     1\n",
       "Name: bmi, Length: 418, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['bmi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.bmi=data.bmi.fillna(28.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_bmi=data.bmi.mean()\n",
    "#missing_bmi = float(\"{:.1f}\".format(missing_bmi))\n",
    "#missing_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.bmi=data.bmi.fillna(missing_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.7</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>18234</td>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>28.7</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>44873</td>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>19723</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>37544</td>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>44679</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0      9046    Male  67.0             0              1          Yes   \n",
       "1     51676  Female  61.0             0              0          Yes   \n",
       "2     31112    Male  80.0             0              1          Yes   \n",
       "3     60182  Female  49.0             0              0          Yes   \n",
       "4      1665  Female  79.0             1              0          Yes   \n",
       "...     ...     ...   ...           ...            ...          ...   \n",
       "5105  18234  Female  80.0             1              0          Yes   \n",
       "5106  44873  Female  81.0             0              0          Yes   \n",
       "5107  19723  Female  35.0             0              0          Yes   \n",
       "5108  37544    Male  51.0             0              0          Yes   \n",
       "5109  44679  Female  44.0             0              0          Yes   \n",
       "\n",
       "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0           Private          Urban             228.69  36.6  formerly smoked   \n",
       "1     Self-employed          Rural             202.21  28.7     never smoked   \n",
       "2           Private          Rural             105.92  32.5     never smoked   \n",
       "3           Private          Urban             171.23  34.4           smokes   \n",
       "4     Self-employed          Rural             174.12  24.0     never smoked   \n",
       "...             ...            ...                ...   ...              ...   \n",
       "5105        Private          Urban              83.75  28.7     never smoked   \n",
       "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
       "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
       "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
       "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
       "\n",
       "      stroke  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "5105       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  \n",
       "\n",
       "[5110 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['bmi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    2994\n",
       "Male      2115\n",
       "Other        1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                5110 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data  Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(feature):\n",
    "    stroke = data[data['stroke']==1][feature].value_counts()\n",
    "    #notstroke = data[data['stroke']==0][feature].value_counts()\n",
    "    df = pd.DataFrame([stroke])\n",
    "    df.index = ['stroke']\n",
    "    df.plot(kind='bar',stacked=0, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain = [data] \n",
    "for dataset in datatrain:\n",
    "    dataset.loc[ (dataset['age'] <=2), 'age'] = 0  #Childhood\n",
    "    dataset.loc[(dataset['age'] > 2) & (dataset['age'] <= 39), 'age'] = 1 #Young  Adults\n",
    "    dataset.loc[(dataset['age'] > 39) & (dataset['age'] <= 59), 'age'] = 2 #Middle -Aged Adults\n",
    "    dataset.loc[ dataset['age'] > 59, 'age'] = 3 #old Adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in datatrain:\n",
    "    dataset.loc[ (dataset['bmi'] <= 18.5), 'bmi'] = 0\n",
    "    dataset.loc[(dataset['bmi'] > 18.5) & (dataset['bmi'] <= 24.9),'bmi'] = 1\n",
    "    dataset.loc[(dataset['bmi'] > 24.9) & (dataset['bmi'] <= 29.9),'bmi'] = 2\n",
    "    dataset.loc[ dataset['bmi'] > 29.9, 'bmi'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI\tWeight Status\n",
    "[0=Below 18.5\tUnderweight]\n",
    "[1=18.5 – 24.9\tNormal or Healthy Weight]\n",
    "[2=25.0 – 29.9\tOverweight]\n",
    "[3=30.0 and Above\tObese]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart('bmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart('ever_married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart('work_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart('Residence_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_chart('smoking_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Featuring \n",
    "datatrain = [data] \n",
    "sex_mapping = {\"Male\": 0, \"Female\": 1,\"Other\": 2}\n",
    "for dataset in datatrain:\n",
    "    dataset['gender'] = dataset['gender'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>3.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>3.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0          0  3.0             0              1          Yes        Private   \n",
       "1          1  3.0             0              0          Yes  Self-employed   \n",
       "2          0  3.0             0              1          Yes        Private   \n",
       "3          1  2.0             0              0          Yes        Private   \n",
       "4          1  3.0             1              0          Yes  Self-employed   \n",
       "...      ...  ...           ...            ...          ...            ...   \n",
       "5105       1  3.0             1              0          Yes        Private   \n",
       "5106       1  3.0             0              0          Yes  Self-employed   \n",
       "5107       1  1.0             0              0          Yes  Self-employed   \n",
       "5108       0  2.0             0              0          Yes        Private   \n",
       "5109       1  2.0             0              0          Yes       Govt_job   \n",
       "\n",
       "     Residence_type  avg_glucose_level  bmi   smoking_status  stroke  \n",
       "0             Urban             228.69  3.0  formerly smoked       1  \n",
       "1             Rural             202.21  2.0     never smoked       1  \n",
       "2             Rural             105.92  3.0     never smoked       1  \n",
       "3             Urban             171.23  3.0           smokes       1  \n",
       "4             Rural             174.12  1.0     never smoked       1  \n",
       "...             ...                ...  ...              ...     ...  \n",
       "5105          Urban              83.75  2.0     never smoked       0  \n",
       "5106          Urban             125.20  3.0     never smoked       0  \n",
       "5107          Rural              82.99  3.0     never smoked       0  \n",
       "5108          Rural             166.29  2.0  formerly smoked       0  \n",
       "5109          Urban              85.28  2.0          Unknown       0  \n",
       "\n",
       "[5110 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_mapping = {\"No\": 0, \"Yes\": 1}\n",
    "for dataset in datatrain:\n",
    "    dataset['ever_married'] = dataset['ever_married'].map(marriage_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(data['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(data['age'])\n",
    "#data['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Private', 'Govt_job', 'Self-employed', 'children', 'Never_worked']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worktype=list(set(data[\"work_type\"]))\n",
    "worktype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_mapping = {'Private':0, 'Self-employed':1, 'Govt_job':2, 'Never_worked':3, 'children':4}\n",
    "for dataset in datatrain:\n",
    "    dataset['work_type'] = dataset['work_type'].map(work_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "residence_mapping = {\"Urban\": 0, \"Rural\": 1}\n",
    "for dataset in datatrain:\n",
    "    dataset['Residence_type'] = dataset['Residence_type'].map(residence_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_mapping = {'Unknown':3, 'never smoked':0, 'smokes':1, 'formerly smoked':2}\n",
    "for dataset in datatrain:\n",
    "    dataset['smoking_status'] = dataset['smoking_status'].map(smoking_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoking=list(set(data[\"smoking_status\"]))\n",
    "#smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228.69</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202.21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82.99</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0          0  3.0             0              1             1          0   \n",
       "1          1  3.0             0              0             1          1   \n",
       "2          0  3.0             0              1             1          0   \n",
       "3          1  2.0             0              0             1          0   \n",
       "4          1  3.0             1              0             1          1   \n",
       "...      ...  ...           ...            ...           ...        ...   \n",
       "5105       1  3.0             1              0             1          0   \n",
       "5106       1  3.0             0              0             1          1   \n",
       "5107       1  1.0             0              0             1          1   \n",
       "5108       0  2.0             0              0             1          0   \n",
       "5109       1  2.0             0              0             1          2   \n",
       "\n",
       "      Residence_type  avg_glucose_level  bmi  smoking_status  stroke  \n",
       "0                  0             228.69  3.0               2       1  \n",
       "1                  1             202.21  2.0               0       1  \n",
       "2                  1             105.92  3.0               0       1  \n",
       "3                  0             171.23  3.0               1       1  \n",
       "4                  1             174.12  1.0               0       1  \n",
       "...              ...                ...  ...             ...     ...  \n",
       "5105               0              83.75  2.0               0       0  \n",
       "5106               0             125.20  3.0               0       0  \n",
       "5107               1              82.99  3.0               0       0  \n",
       "5108               1             166.29  2.0               2       0  \n",
       "5109               0              85.28  2.0               3       0  \n",
       "\n",
       "[5110 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitng Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =data.drop(['stroke'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.25,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(xtest)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.96      0.93      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347630672926449"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(ytest,pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952054794520548"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#60% data\n",
    "atrain,atest,btrain,btest=train_test_split(x,y,test_size=.60,random_state=1)\n",
    "model.score(atest,btest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512720156555773"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data\n",
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc= RandomForestClassifier()\n",
    "rfc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predrfc=rfc.predict(xtest)\n",
    "predrfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1222\n",
      "           1       0.16      0.05      0.08        56\n",
      "\n",
      "    accuracy                           0.95      1278\n",
      "   macro avg       0.56      0.52      0.53      1278\n",
      "weighted avg       0.92      0.95      0.93      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predrfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1206   16]\n",
      " [  53    3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predrfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460093896713615"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predrfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460093896713615"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9895629484670581"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#60% test data\n",
    "rfc.score(atest,btest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864970645792563"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data\n",
    "rfc.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DTC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddtc=dtc.predict(xtest)\n",
    "preddtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1222\n",
      "           1       0.12      0.18      0.14        56\n",
      "\n",
      "    accuracy                           0.91      1278\n",
      "   macro avg       0.54      0.56      0.55      1278\n",
      "weighted avg       0.92      0.91      0.91      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,preddtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1148,   74],\n",
       "       [  46,   10]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ytest,preddtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061032863849765"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,preddtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061032863849765"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794520547945206"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#60% test data\n",
    "dtc.score(atest,btest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765166340508806"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data\n",
    "dtc.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predgnb=gnb.predict(xtest)\n",
    "predgnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1222\n",
      "           1       0.17      0.57      0.26        56\n",
      "\n",
      "    accuracy                           0.86      1278\n",
      "   macro avg       0.57      0.72      0.59      1278\n",
      "weighted avg       0.94      0.86      0.89      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predgnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1062  160]\n",
      " [  24   32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predgnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560250391236307"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predgnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560250391236307"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNNC=KNeighborsClassifier(n_neighbors=61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=61)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predknnc=KNNC.predict(xtest)\n",
    "predknnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.96      0.93      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predknnc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predknnc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNC.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952054794520548"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#60% test data\n",
    "KNNC.score(atest,btest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512720156555773"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data\n",
    "KNNC.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(max_features=0.5, max_samples=0.5, n_estimators=500)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "BC = BaggingClassifier(n_estimators = 500, max_samples = 0.5, max_features = 0.5)\n",
    "BC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predbc=BC.predict(xtest)\n",
    "predbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.96      0.93      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "GBC= GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predgbc=GBC.predict(xtest)\n",
    "predgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.29      0.04      0.06        56\n",
      "\n",
      "    accuracy                           0.95      1278\n",
      "   macro avg       0.62      0.52      0.52      1278\n",
      "weighted avg       0.93      0.95      0.94      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538341158059468"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predgbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538341158059468"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  ExtraTreesClassifier\n",
    "ETC = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predETC=ETC.predict(xtest)\n",
    "predETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1222\n",
      "           1       0.12      0.09      0.10        56\n",
      "\n",
      "    accuracy                           0.93      1278\n",
      "   macro avg       0.54      0.53      0.53      1278\n",
      "weighted avg       0.92      0.93      0.93      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predETC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1184   38]\n",
      " [  51    5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predETC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9303599374021909"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9303599374021909"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETC.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelss = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1, input_shape=[10], activation='tanh'),\n",
    "    tf.keras.layers.Dense(1, input_shape=[10], activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelss.compile(\n",
    "optimizer='adamax',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy']\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelss.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "160/160 [==============================] - 0s 550us/step - loss: 0.2013 - accuracy: 0.7407\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 654us/step - loss: 0.0863 - accuracy: 0.9513\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 623us/step - loss: 0.0544 - accuracy: 0.9513\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 673us/step - loss: 0.0476 - accuracy: 0.9513\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0465 - accuracy: 0.9513\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 617us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 579us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 438us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 677us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 692us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 596us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 671us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 611us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 661us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 563us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 666us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 623us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 818us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 742us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 512us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 636us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 564us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 596us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 486us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 541us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 586us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 661us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 537us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 717us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 711us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 605us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 620us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 661us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 577us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 627us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 648us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 608us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 605us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 655us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 520us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 497us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 517us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 59/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 477us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 522us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 597us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 779us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 560us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 527us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 490us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 457us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 502us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 537us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 589us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 489us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 548us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 547us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 667us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 648us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 631us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 468us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 521us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 711us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 616us/step - loss: 0.0463 - accuracy: 0.9513\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 548us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 507us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 518us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 564us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 546us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 540us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 473us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 533us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 510us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 616us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 490us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 571us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 467us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 466us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 477us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 545us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 474us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 551us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 498us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 597us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 463us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 664us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 510us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 548us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 461us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 486us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 571us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 692us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 612us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 584us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 582us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 711us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 587us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 514us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 525us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 507us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 474us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 601us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 717us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 667us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 539us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 543us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 599us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 494us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 553us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 474us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 534us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 456us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 498us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 564us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 662us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 723us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 692us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 667us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 648us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 605us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0463 - accuracy: 0.9513\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 586us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 494us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 544us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 517us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 518us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 516us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 455us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 609us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 736us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 667us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 711us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 742us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 673us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 667us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 603us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 516us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 608us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 176/500\n",
      "160/160 [==============================] - 0s 619us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 586us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 600us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 622us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 736us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 785us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 842us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 532us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 745us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 636us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 696us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 792us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 711us/step - loss: 0.0464 - accuracy: 0.95130s - loss: 0.0500 - accuracy: 0.\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 736us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 773us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 605us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0463 - accuracy: 0.9513\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 476us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 455us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 527us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 576us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 523us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 552us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 623us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 636us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 704us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 673us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 614us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 528us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 528us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 523us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 499us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 568us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 617us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 551us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 544us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 569us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 454us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 234/500\n",
      "160/160 [==============================] - 0s 455us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 517us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 486us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 522us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 478us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 617us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 528us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 490us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 546us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 643us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 534us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 621us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 516us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 617us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 607us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 493us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 443us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 459us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 467us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 559us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 554us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 547us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 617us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 543us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 613us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 611us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 443us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 534us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 538us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 728us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 553us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 658us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 565us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 499us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 596us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 292/500\n",
      "160/160 [==============================] - 0s 583us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 540us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 610us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 577us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 565us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 586us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 481us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 611us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 673us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 486us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 539us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 312/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 523us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 583us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 686us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 603us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 644us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 472us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 455us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 502us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 461us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 541us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 463us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 514us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 541us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 673us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 654us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 752us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 684us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 611us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 655us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 517us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 517us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.95130s - loss: 0.0496 - accuracy: 0.\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 611us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 604us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 586us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 566us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 596us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 350/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 599us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 465us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 515us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 564us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 474us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 523us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 460us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 514us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 545us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 541us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 501us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 603us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 558us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 577us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 682us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 534us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 648us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 623us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 609us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 554us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 589us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 521us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 611us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 623us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 517us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 499us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 499us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 497us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 601us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 611us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 492us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 408/500\n",
      "160/160 [==============================] - 0s 553us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 496us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 562us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 586us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 605us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 507us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 447us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 516us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 444us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 488us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 486us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 480us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 646us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 579us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 602us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 556us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 711us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 574us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 507us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 499us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 523us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 530us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 511us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 623us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 529us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0465 - accuracy: 0.9513\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0467 - accuracy: 0.9513\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0468 - accuracy: 0.9513\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 598us/step - loss: 0.0471 - accuracy: 0.9513\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 599us/step - loss: 0.0474 - accuracy: 0.9513\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0477 - accuracy: 0.9513\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0481 - accuracy: 0.9513\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0484 - accuracy: 0.9513\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0487 - accuracy: 0.9513\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 573us/step - loss: 0.0492 - accuracy: 0.9513\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 623us/step - loss: 0.0495 - accuracy: 0.9513\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 468us/step - loss: 0.0498 - accuracy: 0.9513\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 468us/step - loss: 0.0500 - accuracy: 0.9513\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 505us/step - loss: 0.0501 - accuracy: 0.9513\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 485us/step - loss: 0.0502 - accuracy: 0.9513\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 517us/step - loss: 0.0503 - accuracy: 0.9513\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0503 - accuracy: 0.9513\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 565us/step - loss: 0.0501 - accuracy: 0.9513\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 550us/step - loss: 0.0499 - accuracy: 0.9513\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0498 - accuracy: 0.9513\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.0497 - accuracy: 0.9513\n",
      "Epoch 466/500\n",
      "160/160 [==============================] - 0s 531us/step - loss: 0.0496 - accuracy: 0.9513\n",
      "Epoch 467/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 592us/step - loss: 0.0495 - accuracy: 0.9513\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 536us/step - loss: 0.0493 - accuracy: 0.9513\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0491 - accuracy: 0.9513\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0487 - accuracy: 0.9513\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 592us/step - loss: 0.0483 - accuracy: 0.9513\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 594us/step - loss: 0.0480 - accuracy: 0.9513\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 542us/step - loss: 0.0477 - accuracy: 0.9513\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 686us/step - loss: 0.0474 - accuracy: 0.9513\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 555us/step - loss: 0.0471 - accuracy: 0.9513\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 637us/step - loss: 0.0470 - accuracy: 0.9513\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 607us/step - loss: 0.0468 - accuracy: 0.9513\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0467 - accuracy: 0.9513\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 578us/step - loss: 0.0466 - accuracy: 0.9513\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 561us/step - loss: 0.0465 - accuracy: 0.9513\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 683us/step - loss: 0.0465 - accuracy: 0.9513\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 654us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 625us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 729us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 684us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 960us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 674us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 494us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.0463 - accuracy: 0.9513\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 502us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 486us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 562us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 448us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 492us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 586us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 664us/step - loss: 0.0463 - accuracy: 0.9513\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 484us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 443us/step - loss: 0.0464 - accuracy: 0.9513\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 443us/step - loss: 0.0464 - accuracy: 0.9513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e47bffdf0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelss.fit(x,y,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelss.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(multi_class='multinomial', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predlr=LR.predict(xtest)\n",
    "predlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.96      0.93      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDC = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsgdc=SGDC.predict(xtest)\n",
    "predsgdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.96      0.93      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predsgdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predsgdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predsgdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "QDA = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDA.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predqda=QDA.predict(xtest)\n",
    "predqda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      1222\n",
      "           1       0.20      0.57      0.29        56\n",
      "\n",
      "    accuracy                           0.88      1278\n",
      "   macro avg       0.59      0.73      0.61      1278\n",
      "weighted avg       0.94      0.88      0.91      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predqda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1092  130]\n",
      " [  24   32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predqda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794992175273866"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predqda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794992175273866"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDA.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ABC = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predabc=ABC.predict(xtest)\n",
    "predabc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.50      0.02      0.03        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.73      0.51      0.51      1278\n",
      "weighted avg       0.94      0.96      0.94      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predabc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1221    1]\n",
      " [  55    1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predabc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predabc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLPC = MLPClassifier(hidden_layer_sizes=(100),\n",
    "                     activation='relu', \n",
    "                     solver='adam', \n",
    "                     alpha=0.0001,batch_size= 'auto',\n",
    "                     learning_rate='constant',\n",
    "                     learning_rate_init=0.001,\n",
    "                     power_t=0.5, max_iter=200,\n",
    "                     shuffle=True,\n",
    "                     random_state=None,\n",
    "                     tol=0.0001,\n",
    "                     verbose=False,\n",
    "                     warm_start=False, \n",
    "                     momentum=0.9,\n",
    "                     nesterovs_momentum=True,\n",
    "                     early_stopping=False,\n",
    "                     validation_fraction=0.1,\n",
    "                     beta_1=0.9,\n",
    "                     beta_2=0.999,\n",
    "                     epsilon=1e-08)\n",
    "#MLPC = MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,solver='lbfgs')\n",
    "#MLPC = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=100)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPC.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predmlpc=MLPC.predict(xtest)\n",
    "predmlpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.96      0.93      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predmlpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predmlpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predmlpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPC.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelss=[('model',model),('rfc',rfc),('dtc',dtc),('gnb',gnb),('KNNC',KNNC),('BC',BC),('GBC',GBC),('ETC',ETC),('LR',LR),('SGDC',SGDC),('QDA',QDA),('ABC',ABC),('MLPC',MLPC)]\n",
    "vcf=VotingClassifier(estimators=modelss,voting='hard',weights=[2,1,1,1,1,1,1,1,1,1,1,1,1],flatten_transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9561815336463224"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf.fit(xtrain,ytrain)\n",
    "vcf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predvcf=vcf.predict(xtest)\n",
    "predvcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1222\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.96      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.96      0.93      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Polash\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predvcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222    0]\n",
      " [  56    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest,predvcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
